{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dropbox' 'facebook' 'gmail' 'google-drive' 'hulu' 'instagram'\n",
      " 'messenger' 'netflix' 'pandora' 'pinterest' 'reddit' 'spotify' 'twitter'\n",
      " 'youtube'] 14 288\n",
      "['dropbox_download' 'dropbox_upload' 'facebook_scroll-newsfeed'\n",
      " 'facebook_search-page' 'gmail_open-email' 'gmail_send-email'\n",
      " 'google-drive_download' 'google-drive_upload' 'hulu_scroll-home'\n",
      " 'hulu_watch-video' 'instagram_IgSearchBrowse' 'instagram_send-message'\n",
      " 'messenger_send-message' 'netflix_browse-home' 'netflix_watch-video'\n",
      " 'pandora_play-music' 'pandora_search-music' 'pinterest_tap-board'\n",
      " 'reddit_browse' 'reddit_post' 'spotify_play-music' 'spotify_search-music'\n",
      " 'twitter_post-tweet' 'twitter_scroll-feed' 'twitter_send-message'\n",
      " 'youtube_play-video' 'youtube_search'] 27\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Yuqiang (Ethan) Heng\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "scenario = 'random' #deterministic, random or wild\n",
    "if scenario == 'random':\n",
    "    mypath = './Data/Randomized Automated Data'\n",
    "elif scenario == 'deterministic':\n",
    "    mypath = './Data/Deterministic Automated Data'\n",
    "elif scenario == 'wild':\n",
    "    mypath = './Data/Wild Test Data'\n",
    "else:\n",
    "    raise NameError('Dataset Not Supported')\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "apps = np.unique([f.split('_')[0] for f in onlyfiles])\n",
    "print(apps, len(apps), len(onlyfiles))\n",
    "app_actions = np.unique(['_'.join(f.split('_')[:2]) for f in onlyfiles])\n",
    "print(app_actions, len(app_actions))\n",
    "\n",
    "sel_apps = apps\n",
    "sel_app_files = {i:[] for i in sel_apps}\n",
    "\n",
    "for fname in onlyfiles:\n",
    "    app_name = fname.split('_')[0]\n",
    "    if app_name in sel_apps:\n",
    "        sel_app_files[app_name].append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_columns = ['ip.src', 'srcport', 'ip.dst', 'dstport', 'protocal']\n",
    "\n",
    "def get_protocal(row):\n",
    "    if not pd.isnull(row['tcp.len']):\n",
    "        return 'TCP'\n",
    "    elif not pd.isnull(row['udp.length']):\n",
    "        return 'UDP'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def get_srt_port(row):\n",
    "    if not pd.isnull(row['tcp.len']):\n",
    "        return row['tcp.srcport']\n",
    "    elif not pd.isnull(row['udp.length']):\n",
    "        return row['udp.srcport']\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def get_dst_port(row):\n",
    "    if not pd.isnull(row['tcp.len']):\n",
    "        return row['tcp.dstport']\n",
    "    elif not pd.isnull(row['udp.length']):\n",
    "        return row['udp.dstport']\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "columns = ['frame.number','frame.time','frame.len','frame.cap_len','ip.hdr_len',\n",
    "           'ip.dsfield.ecn','ip.len','ip.frag_offset','ip.ttl','ip.proto','ip.src',\n",
    "           'ip.dst','tcp.hdr_len','tcp.len','tcp.srcport','tcp.dstport','tcp.flags.ns',\n",
    "           'tcp.flags.fin','tcp.window_size_value','tcp.urgent_pointer','tcp.option_kind',\n",
    "           'tcp.option_len','udp.srcport','udp.dstport','udp.length']\n",
    "\n",
    "def compute_flow_features(df):\n",
    "    flow_features = {}\n",
    "    flow_features['total_num_pkts'] = len(df)\n",
    "    pkt_size = df['ip.len'].astype(float)\n",
    "    flow_features['total_num_bytes'] = pkt_size.sum()\n",
    "    flow_features['min_pkt_size'] = pkt_size.min()\n",
    "    flow_features['max_pkt_size'] = pkt_size.max()\n",
    "    flow_features['mean_pkt_size'] = pkt_size.mean()\n",
    "    flow_features['std_pkt_size'] = pkt_size.std()\n",
    "    iat = pd.to_datetime(df['frame.time']).diff(1).dt.total_seconds().iloc[1:]\n",
    "    flow_features['min_iat'] = iat.min()\n",
    "    flow_features['max_iat'] = iat.max()\n",
    "    flow_features['mean_iat'] = iat.mean()\n",
    "    flow_features['std_iat'] = iat.std()\n",
    "    flow_features['dur'] = iat.sum()\n",
    "    return flow_features\n",
    "\n",
    "def process_df_by_flow(df):\n",
    "    df['protocal'] = df.apply(lambda row: get_protocal(row), axis=1)\n",
    "    df['srcport'] = df.apply(lambda row: get_srt_port(row), axis=1)\n",
    "    df['dstport'] = df.apply(lambda row: get_dst_port(row), axis=1)  \n",
    "    df_flow = pd.DataFrame()\n",
    "    flow_columns = ['ip.src', 'srcport', 'ip.dst', 'dstport', 'protocal']\n",
    "    ul_flows = {}\n",
    "    dl_flows = {}\n",
    "    for flow, flow_df in df.groupby(by=flow_columns):\n",
    "        if flow[0].split('.')[0] == '10':\n",
    "            ul_flows[flow] = compute_flow_features(flow_df)\n",
    "        else:\n",
    "            dl_flows[flow] = compute_flow_features(flow_df)\n",
    "    for ul_flow, ul_flow_features in ul_flows.items():\n",
    "        for dl_flow, dl_flow_features in dl_flows.items():\n",
    "            if (ul_flow[0] == dl_flow[2]) & (ul_flow[2] == dl_flow[0]) & (ul_flow[1] == dl_flow[3]) & (ul_flow[3] == dl_flow[1]) & (ul_flow[4] == dl_flow[4]):\n",
    "                ul_flow_features = {'ul_'+feature_name:feature for feature_name,feature in ul_flow_features.items()}\n",
    "                dl_flow_features = {'dl_'+feature_name:feature for feature_name,feature in ul_flow_features.items()}\n",
    "                bi_flow_features = {**ul_flow_features,**dl_flow_features}\n",
    "                bi_flow_features['ip_A'] = ul_flow[0]\n",
    "                bi_flow_features['port_A'] = ul_flow[1]\n",
    "                bi_flow_features['ip_B'] = ul_flow[2]\n",
    "                bi_flow_features['port_B'] = ul_flow[3]\n",
    "                bi_flow_features['protocal'] = ul_flow[4]\n",
    "                df_flow = df_flow.append(bi_flow_features, ignore_index=True)\n",
    "    return df_flow\n",
    "\n",
    "def clean_up_duplicate(row):\n",
    "    if len(str(row['ip.hdr_len']).split(','))>1:\n",
    "        row['ip.hdr_len'] = str(row['ip.hdr_len']).split(',')[1]\n",
    "    if len(str(row['ip.len']).split(','))>1:\n",
    "        row['ip.len'] = str(row['ip.len']).split(',')[1]\n",
    "    else:\n",
    "        row['ip.len'] = str(row['ip.len']).split(',')[0]\n",
    "    if len(row['ip.src'].split(','))>1:\n",
    "        row['ip.src'] = row['ip.src'].split(',')[1]\n",
    "    if len(row['ip.dst'].split(','))>1:\n",
    "        row['ip.dst'] = row['ip.dst'].split(',')[1]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\Anaconda3\\envs\\p37\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname CDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing random scenario data.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for app in sel_apps:\n",
    "    integrity = True\n",
    "    df_app = pd.DataFrame()\n",
    "    for fname in sel_app_files[app]:\n",
    "        action = fname.split('_')[1]\n",
    "        df = pd.read_csv(join(mypath,fname),usecols = columns,low_memory=False)\n",
    "        df = df[df['ip.src'].notna()]\n",
    "        \n",
    "        df = df.apply(lambda row:clean_up_duplicate(row),axis=1)\n",
    "        \n",
    "        # Remove self loop pkts\n",
    "        df = df[(df['ip.src']!='127.0.0.1') & (df['ip.dst']!='127.0.0.1')]\n",
    "        try:\n",
    "            df_flow = process_df_by_flow(df)\n",
    "            df_flow['action'] = action\n",
    "            df_app = df_app.append(df_flow)\n",
    "        except:\n",
    "            integrity = False\n",
    "            print('\\n Error while processing {}. \\n'.format(fname))\n",
    "\n",
    "    df_app['app'] = app\n",
    "    \n",
    "    if integrity:\n",
    "        df_all = df_all.append(df_app)\n",
    "        \n",
    "df_all.to_csv('./Processed Data/{}_scenario_bi_flow_features.csv'.format(scenario))\n",
    "print('Finished processing {} scenario data.'.format(scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
